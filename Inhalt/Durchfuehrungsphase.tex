% !TEX root = ../Projektdokumentation.tex
\section{Durchführungsphase}
\label{sec:Durchführungsphase}

\subsection{Vorbereitung der Tests}
\label{sec:VorbereitungTests}

\subsubsection{Vorbereiten der Hardware}
\label{sec:VorbereitungHardware}
Eine ausrangierte DELL Precision Workstation dient als Hardwareplattform für das Projekt. Die Ausstattung von 32 Gigabyte Arbeitsspeicher und einem Intel Xeon Hochleistungsprozessor ist ausreichend für den Betrieb von mehreren virtuellen Maschinen.

Um den Bedingungen in einem \glqq{}echtem\grqq{} Rechencenter möglichst nahe zu kommen, wird der \ac{VM}-Hypervisor mit zwei Netzwerkschnittstellen ausgestattet. Ein Interface ist für die Kommunikation mit dem Hypervisor selbst vorgesehen (sogenanntes Management-\ac{LAN}), und eine weitere Netzwerkschnittstelle wird von den virtuellen Maschinen benutzt, um im Netzwerk erreichbar zu sein.

Da die vorgesehene Workstation mit nur einem RJ45 Port ausgestattet war, wurde aus einer anderen die zusätzliche Netzwerkkarte entfernt und in diese eingebaut. Der Umbau gestaltete sich dank PCIe-Steckplatz als unkompliziert und war ohne Werkzeuggebrauch möglich.

\subsubsection{Installation des Hypervisors}
\label{sec:InstallationHypervisor}
Um die gegeben Ressourcen optimal auszunutzen, wird ein sogenannter Typ 1-Hypervisor eingesetzt. Dieser kommuniziert direkt mit der Hardware, ohne dass ein anderes Betriebssystem zum Einsatz kommt. Der Markt an \ac{VM}-Hypervisoren ist stark umkämpft; neben den bekannten Lösungen von den \glqq{}Platzhirschen\grqq{} Microsoft, VMware und Citrix existiert eine Vielzahl an kleinen, teils auch quelloffenen, Virtualisierungsplattformen. Für dieses Projekt wird das System \glqq{}\ac{ESXi}\grqq{} von VMware in der Version 6.7 verwendet, das auch in den firmeneigenen Rechenzentren zum Einsatz kommt.

Die Installation gestaltet sich als simpel. Nachdem wichtige UEFI-Optionen angepasst wurden (ausschließliche Verwendung von UEFI statt legacy-BIOS; Aktivierung der hardewareseitigen Unterstützung für Virtualisierung \glqq{}Intel VT-x\grqq{}) wird das System von einem USB-Datenträger, der zuvor mit dem ac{ESXi}-Image geflasht wurde, gestartet. Nachdem die für die Installation zu benutzende Festplatte ausgewählt, und ein Root-Passwort vergeben wurde, startet der Installationsvorgang. Nach abgeschlossener Installation muss noch eine IP-Adresse für das Managementnetzwerk vergeben werden.

Die restliche Konfiguration geschieht bequem über eine Weboberfläche. Der Lizenzschlüssel wird hinterlegt, die zweite Festplatte als Datastore eingebunden, und das Netzwerk für die virtuellen Maschinen konfiguriert (siehe Abbildung \ref{screen:vmnetwork}). Hierzu wird ein neuer virtueller Switch für den zweiten Netzwerkport (der, der nicht mit dem Management-\ac{LAN} belegt ist) erstellt und mit einer neuen Port Group versehen. Diese Port Groups werden in ac{ESXi} verwendet, um logische Netzwerkschnittstellen bereit zu stellen und zu verwalten. 

\subsubsection{Installation der virtuellen Maschinen}
\label{sec:InstallationVMs}
Für virtuelle Maschinen muss in der ac{ESXi}-Weboberfläche zunächst die Systemkonfiguration festgelegt werden. Hierfür werden die für die \ac{VM} vorgesehene \ac{CPU}-Kerne, Arbeits- und Massenspeicherspeicherkapazität (siehe Abbildung \ref{screen:vmcreation}) sowie die zu benutzenden Port Groups eingestellt. Abschließend wird in ein virtuelles DVD-Laufwerk das ISO-Abbild für das entsprechende zu installierende Betriebssystem eingehängt, und die virtuelle Maschine gestartet. Die anschließende Betriebssysteminstallation kann über eine emulierte Browser-Konsole durchgeführt werden.

Um in diesem Testsystem eine möglichst nah an das Firmennetzwerk heranzukommen, wurden drei Betriebssysteme für die Server ausgewählt: Windows Server 2019, Ubuntu 18.04 LTS sowie Debian 10.3. Die Installation der Systeme verlief ohne Probleme.

\subsubsection{Installation von \glqq{}Icinga\grqq{}}
\label{sec:InstallationIcinga}
Die Installation von \glqq{}Icinga\grqq{} unter Ubuntu beginnt mit dem Aufruf der Rootshell und einem anschließendem kompletten Systemupdate. Danach werden mittels Paketverwaltung die wichtigsten Ressourcen installiert; die Pakete \code{icinga2} und \code{icingacli} sind für die Monitoring-Engine an sich sowie die Verwaltung über Kommandozeile zuständig. \code{monitoring-plugins} installiert die grundsätzlichen Monitoringmethoden (z.B. Ping) für Nagios-kompatible Systeme wie \glqq{}Icinga\grqq{}.

Zusätzlich muss noch eine passende Datenbank aufgesetzt werden, hier fiel die Entscheidung aufgrund der firmeninteren Verbreitung sowie der In-Memory Unterstützung auf MySQL. Durch Installation der Pakete \code{mysql-server} und \code{mysql-client} werden ein MySQL-Server und ein MySQL-Client bereitgestellt, das Skript \code{mysql\_secure\_installation} (siehe Abbildung \ref{screen:mysqlsecure}) verbessert die Sicherheit der Installation durch Maßnahmen wie das Entfernen von anonymen Accounts oder die Absicherung des root-Accounts.

Im nächsten Schritt muss die Schnittstelle zwischen \glqq{}Icinga Data Output\grqq{} (Exportfunktion für Monitoringdaten) und MySQL geschaffen werden, damit die gesammelten Daten auch gespeichert werden können. Dies geschieht durch Installation des Pakets \code{icinga2-ido-mysql}. Anschließend kann das Webinterface \code{icingaweb2} installiert werden.

Beim Versuch, die über die Paketverwaltung verfügbare Version des Web-Frontends aufzurufen, wird lediglich ein \ac{PHP}-Fehler (siehe Abbildung \ref{screen:phperror}) angezeigt. Nach einer umfangreichen Recherche ergab sich, dass dieser Fehler durch einen Bug verursacht wird, wodurch \glqq{}Icinga\grqq{} nicht mit bestimmten \ac{PHP} 7.2 Plugins kompatibel ist. Dieser Fehler wurde bereits Mitte 2018 behoben, allerdings ist der Bugfix anscheinend nicht in das Paket eingespielt worden. Das Problem wurde gelöst, indem die aktuelle Version von \glqq{}Icinga Web 2\grqq{} vom öffentlichen Github-Repository nach \code{/usr/share/icingaweb2} geklont wurde.

Ist \glqq{}Icinga Web 2\grqq{} fertig installiert, muss noch ein Benutzer für die MySQL-Datenbank erstellt werden. Abschließend wird IDO mittels \code{icinga2 feature enable command ido-mysql} aktiviert, und ein Setup-Token mit \code{icingacli setup token create} generiert werden. Nach einem Neustart des icinga2-Dienstes (\code{systemctl restart icinga2}) ist \glqq{}Icinga 2\grqq{} bereit über die Webschnittstelle eingerichtet zu werden. Eine komplette (nachträglich optimierte) Liste an Befehlen, die für eine komplette Installation unter Ubuntu 18.04 ausgeführt werden müssen, findet sich im \Anhang{app:skript}.

\paragraph{Einrichtung über Webfrontend}
Im Browser wird nun (IP-Adresse des Servers)/icingaweb2/setup aufgerufen, um den Konfigurationsassistenten (siehe Abbildung \ref{screen:konfigassistent}) zu starten. Dieser verlangt nach dem setup token, welcher im vorherigen Schritt generiert wurde. Nach Eingabe dieses tokens wird im ersten Schritt geprüft, ob alle notwendigen \ac{PHP}-Plugins vorhanden sind. In der für diese Projekt durchgeführten Installation fehlten die Plugins \glqq{}PDO-PostgreSQL\grqq{}, welches aufgrund der Verwendung von MySQL nicht benötigt wird, sowie \glqq{}cURL\grqq{}, das mittels \code{apt install php7.2-curl} nachinstalliert wurde.

Im Abschnitt \glqq{}Configuration\grqq{} werden noch kleinere, weitere Einstellungen getroffen, hierbei bietet sich aber meistens an, die Standardeinstellungen beizubehalten. Eine Ausnahme stellt die bevorzugte Authentifizierungsmethode für Benutzer des Frontends dar; hier kann zwischen \ac{LDAP} und einer Datenbank mit Benutzern gewählt werden. Für dieses Projekt wurde aufgrund des geringeren Umfangs letztere Option gewählt, die Konfiguration hierfür findet sich in Abbildung \ref{screen:userdb}.

\paragraph{Einpflegen von Servern}
Ist der Konfigurationsassistent abgeschlossen, müssen die zu überwachenden Server eingepflegt werden. Durch Installation des Plugins \glqq{}Icinga Director\grqq{} kann dies auch über die Webschnittstelle erledigt werden, für dieses Projekt wird darauf verzichtet und die weitergehende Konfiguration geschieht über Anpassung der Konfigurationsdateien unter \code{/etc/icinga2/conf.d/}. Dort können in der Datei \code{hosts.conf} neue Server hinzugefügt werden (Syntax siehe Abbildung \ref{screen:newservers}). Abschließend kann die Syntax der Konfigurationsdateien mittels \code{icinga2 daemon --validate} überprüft werden; nach einem Neustart des \glqq{}Icinga 2\grqq{} Dienstes sind die neuen Hosts im Monitoring verfügbar.

\paragraph{Installation des Agents}
Mit der bisherigen Konfiguration können einfache Checks (z.B. Ping) auf die entsprechenden Server durchgeführt werden. Für aufwendigere Überprüfungen wie Speicherplatzkontrolle muss auf den Servern eine Software installiert werden. Hierfür muss zunächst der Monitoringserver als \glqq{}Master\grqq{} deklariert werden, dies geschieht mittels des Befehls \code{icinga2 node wizard}. Anschließend wird mit \code{sudo icinga2 pki ticket --cn (FQDN)} noch ein \glqq{}Ticket\grqq{} für den angegebenen \ac{FQDN} erstellt, mithilfe dessen der Host die Verbindung zum Master herstellen kann.

Der Host selbst installiert die Software ebenfalls, auf Linux-basierten Systemen besteht dies einfach aus dem Paket \code{icinga2}, für Windows existieren herunterladbare Installationsdateien. Mit Durchführung des Befehls \code{icinga2 node wizard} wird die Konfiguration des Agents abgeschlossen, bei Windows geschieht dies über ein grafisches Userinterface. Nachdem die Adresse des Masters sowie die eben erstellte Ticketnummer angegeben und eventuell Ports angepasst wurden, stellt der Agent eine Verbindung zum Monitoring her.

\subsection{Durchführung der Tests}
\label{sec:DurchführungTests}

\subsubsection{Betriebssystemkompatibilität}
\label{sec:oscompatibility}
Es konnten keine Probleme bei der Integration von anderen Betriebsystemen festgestellt werden. Sowohl unter Ubuntu 18.04, Debian 10 und Windows Server 1809 läuft \glqq{}Icinga 2\grqq{} ohne Probleme. Auch eine Online-Recherche förderte keine Probleme zu Tage, weswegen davon ausgegangen werden kann, dass eine umfassende Betriebssystemkompatibilität gewährleistet ist.

\subsubsection{Überwachung von Leistungsparametern}
\label{sec:ÜberwachungLeistungsparameter}
Das installierte Pluginpaket \code{monitoring-plugins} bringt die benötigten Plugins zur Überwachung der Leistungsparametern (\ac{CPU}-Auslastung, RAM-Belegung und belegter Massenspeicher) mit. Für diese Überprüfungen müssen in \code{/etc/icinga2/conf.d/commands.conf} Definitionen erstellt werden. Am Beispiel in Abbildung \ref{screen:loaddefinition} ist erkenntlich, dass diese Definitionen neben dem auszuführendem Befehl (diese sind als Bash-Skript abgelegt; das Verzeichnis hierfür ist in der Konstante \glqq{}PluginDir\grqq{} gespeichert) auch die zu übergebenden Argumente enthält. Im Beispiel der \ac{CPU}-Auslastung wird mitgegeben, dass der Durchschnitt aller \ac{CPU}-Kerne berechnet (-r) und bei bestimmten Schwellenwerten (--critical) ein Alarm gegeben werden soll-

Ist die Definition erfolgreich validiert, muss sie noch den entsprechenden Hosts zugewiesen. In der Datei \code{/etc/icinga2/conf.d/services.conf} wird hierzu ein Eintrag, wie in Abbildung \ref{screen:service} gezeigt, erstellt; dieser gibt den entsprechenden Befehl (check\_{}command) und die zu überprüfende Instanz (command\_{}endpoint) an, und weist das Überprüfungskommando zum Schluss allen Hosts mit einer Adresse zu (assign where host.address).

Die Überwachung der nach dem Kriterienkatalog benötigten Parameter funktioniert problemlos und die Werte decken sich mit den von den Systemen ermittelten Auslastungen. Somit ist \glqq{}Icinga 2\grqq{} auch hierfür einsatzfähig.

\subsubsection{Webserverüberwachung}
\label{sec:ÜberwachungWebserver}
Die Überwachung von Webservern muss analog zu den vorhergehenden Checks eingerichtet werden. Das Plugin \glqq{}http\grqq{} übernimmt diese Aufgabe.  In der Abbildung \ref{screen:webserver} ist gut erkenntlich, wie die Antwort der \ac{HTTP}-Abfrage (Statuscode 200 OK) ausgewertet und dargestellt wird. Für die Antwortzeit lassen sich auch hier Schwellenwerte konfigurieren, sodass nicht nur Erreichbarkeit, sondern auch Performance überprüft werden kann. Die Überwachung von Webdiensten ist somit nach den in der Planungsphase aufgestellten Kriterien möglich.

\subsubsection{Grafische Aufbereitung}
\label{sec:GrafischeAufbereitung}
Auf der Startseite lassen sich mehrere Dashboards erstellen, die mithilfe sogenannter \glqq{}Dashlets\grqq{} befüllt werden können. Alle über die Weboberfläche aufrufbaren Menüs haben eine eindeutige \ac{URL}, mit der ein solches Dashlet erstellt werden kann. Somit ist es einfach, sehr angepasste  und frei konfigurierbare Übersichten zu erstellen (siehe Abbildung \ref{screen:dashboard}.

Sollte dies nicht ausreichen, bietet die Entwicklercommunity viele weitere Plugins für diesen Zweck an. Als wichtigstes ist hier \code{dashin-dashboard} vertreten, das schon am Standort Bremen eingesetzt wird, und nach Auskunft der Mitarbeitenden durch die Unterstützung von Hintergrundbildern und Animationen in der Lage ist, noch ansprechendere Dashboards zu erstellen. Auch hier konnten also die vorher definierten Kriterien erfüllt werden.